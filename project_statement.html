<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
    <!-- Name of tab -- >
    <title>Project statement</title>
    
    <!-- Link to CSS styles page -->
    <link rel="stylesheet" href="stylepage.css">  
    <link href="https://fonts.googleapis.com/css2?family=Boldonse&display=swap" rel="stylesheet">
</head>
<body>
    
    <!-- The navigator bar at the top of the screen - links to our other html pages -->
    <div class="page-container">
    <nav class="navigator"> <!-- To design this, use .navigator{ on stylepage.css -->
        <a href="index.html">Home</a>
        <a href="about_elijah.html">About Us: Elijah</a>
        <a href="about_nia.html">About Us: Nia</a>
        <a href="tech_heroes.html">Tech Heroes</a>
        <a href="resources.html">Resources</a>
        <a href="project_statement.html">Project Statement</a>
        <a href="teachable_machines.html">Our Teachable Machine</a>
    </nav>   

     <!-- Title; Use .projectTitle for CSS -->
   <h1 class="projectTitle">Project Statement</h1>
      
    <!-- Our Project Statement -->
   <h2>Project Scope</h2>
   <p class="text"></p>
      
   <h2>Process</h2>
   <p class="text">
We began our project using Google’s Teachable Machines platform, selecting the stages of a banana’s ripeness as our focus. Our goal was to train a model capable of distinguishing between four categories:

  <!-- Bullet Points -->
      <ul>
  <li>Overripe banana (too late in its development)</li>
  <li>Unripe banana (still green)</li>
  <li>Perfect banana</li>
  <li>No banana, which served as a control to test.</li>
      </ul>
     To build our dataset, each team member collected a banana and captured multiple bursts of images using a webcam from different angles. In total, we gathered approximately 200–300 images per class, ensuring a diverse set of examples for training. Once the dataset was complete, we moved on to training the model. At first, the machine successfully distinguished between the different banana stages. However, when we introduced other objects, such as an orange, it misclassified them as overripe bananas. We realized this issue stemmed from the No Banana class, which had only been trained on empty backgrounds. As a result, the model lacked exposure to non-banana objects and defaulted to misclassification. To address this, we expanded the No Banana class by adding roughly 200 additional images featuring a variety of fruits and objects. This provided the model with greater diversity and helped it learn that “no banana” could mean the presence of other items, not just empty space. After retraining, the algorithm improved significantly: it was able to correctly identify both non-banana objects and distinguish them from bananas at different stages of ripeness.
   </p>
      
   <h2>Analysis</h2>
   <p class="text"></p>
      

   <!-- Footer -->
  <footer class="footer"> <!-- To design this .footer{ in stylepage.css -->
      <p>
        Nia Davis, Elijah Warren, and Joe Weckworth - LIS 500 Code and Power Project #3
        - University of Wisconsin-Madison
      </p>
  </footer>
  </div>
</body>

</html>
